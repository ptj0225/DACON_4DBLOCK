{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as T\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import util\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "util.seed_everything(41) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE_TRAIN':380,\n",
    "    'IMG_SIZE_TEST':380,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'LEARNING_RATE_DECREASE': 0.1,\n",
    "    'MIN_LEARNING_RATE': 1e-5,\n",
    "    'BATCH_SIZE':20,\n",
    "    'SEED':41,\n",
    "    'MODEL_NAME':\"v2-s\",\n",
    "    'LABEL_SMOOTH': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG[\"MODEL_NAME\"] == \"b0\":\n",
    "    class BaseModel(nn.Module):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(BaseModel, self).__init__()\n",
    "            self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "            self.backbone.classifier[-1] = nn.Linear(1280, num_classes)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.backbone(x)\n",
    "            x = F.sigmoid(x)\n",
    "            return x\n",
    "            \n",
    "elif CFG[\"MODEL_NAME\"] == \"b4\":\n",
    "    class BaseModel(nn.Module):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(BaseModel, self).__init__()\n",
    "            self.backbone = models.efficientnet_b4(pretrained=True)\n",
    "            self.backbone.classifier[-2] = nn.Dropout(0.7)\n",
    "            self.backbone.classifier[-1] = nn.Linear(1792, num_classes)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.backbone(x)\n",
    "            x = F.sigmoid(x)\n",
    "            return x\n",
    "            \n",
    "elif CFG[\"MODEL_NAME\"] == \"b7\":\n",
    "    class BaseModel(nn.Module):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(BaseModel, self).__init__()\n",
    "            self.backbone = models.efficientnet_b7(pretrained=True)\n",
    "            self.backbone.classifier[-1] = nn.Linear(2560, num_classes)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.backbone(x)\n",
    "            x = F.sigmoid(x)\n",
    "            return x\n",
    "\n",
    "elif CFG[\"MODEL_NAME\"] == \"v2-s\":\n",
    "    class BaseModel(nn.Module):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(BaseModel, self).__init__()\n",
    "            self.backbone = models.efficientnet_v2_s(pretrained=True).features\n",
    "            self.adaptiveavgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "            self.classifier = nn.Sequential(nn.Flatten(),\n",
    "                                            nn.Dropout(0.7), \n",
    "                                            nn.Linear(1280,10))\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.backbone(x)\n",
    "            x = self.adaptiveavgpool(x)\n",
    "            x = self.classifier(x)\n",
    "            x = F.sigmoid(x)\n",
    "            return x\n",
    "\n",
    "elif CFG[\"MODEL_NAME\"] == \"v2-m\":\n",
    "    class BaseModel(nn.Module):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(BaseModel, self).__init__()\n",
    "            self.backbone = models.efficientnet_v2_m(pretrained=True)\n",
    "            self.backbone.classifier[-2] = nn.Dropout(0.7)\n",
    "            self.backbone.classifier[-1] = nn.Linear(1280, num_classes)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.backbone(x)\n",
    "            x = F.sigmoid(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "df = pd.DataFrame()\n",
    "for csv in ['train.csv', 'train_mixup.csv', 'train_rmbg.csv']:\n",
    "    df_ = pd.read_csv(csv, index_col=\"id\")\n",
    "    df = pd.concat([df,df_])\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "train_len = int(len(df) * 0.8)\n",
    "df = df.loc[:,[\"img_path\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]]\n",
    "\n",
    "train_df = df[:train_len]\n",
    "val_df = df[train_len:train_len+1]\n",
    "\n",
    "train_labels = util.get_labels(train_df)\n",
    "val_labels = util.get_labels(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_res= 380):\n",
    "    return T.Compose([\n",
    "                    T.Resize(img_res),\n",
    "                    T.TrivialAugmentWide(),\n",
    "                    T.AugMix(),\n",
    "                    T.RandomPerspective(distortion_scale=0.6, p=0.3),\n",
    "                    T.ColorJitter(brightness=.5, hue=.3),\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                    ])\n",
    "\n",
    "def get_test_transform(img_res=380):\n",
    "    return T.Compose([\n",
    "                    T.Resize(img_res),\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                    ])\n",
    "                            \n",
    "train_dataset = util.CustomDataset(train_df['img_path'].values, train_labels, get_train_transform(CFG['IMG_SIZE_TRAIN']))\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=8)\n",
    "\n",
    "val_dataset = util.CustomDataset(val_df['img_path'].values, val_labels, get_test_transform(CFG['IMG_SIZE_TEST']))\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1 learning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06d3d0677714308b4ffba4b2100fe28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.47685"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a2458ceff346e99fa6e4601d29d279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.47685] Val Loss : [0.45766] Val ACC : [0.80000]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b158abe3e4089a9d82f44cb6b0310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 0.9593437945791726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623d5b75c3bf40ad99df4d4dde84838b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 0.9593437945791726\n",
      "epochs: 2 learning_rate: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdfd068584c4af081d5fbb09dd137c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "\n",
    "labeled = pd.read_csv(\"C:/Users/abc/Desktop/labeled.csv\", index_col=0)\n",
    "labeled = np.array(labeled)\n",
    "\n",
    "for epochs in range(1, CFG['EPOCHS']+1):\n",
    "    save_model_dir = \"./models/Effinet-{0} epochs{1} res{2}.pth\".format(CFG[\"MODEL_NAME\"], epochs, CFG['IMG_SIZE_TRAIN'])\n",
    "    lr = CFG['LEARNING_RATE'] * (CFG['LEARNING_RATE_DECREASE'] ** (epochs - 1))\n",
    "    lr = max(lr, CFG['MIN_LEARNING_RATE'])\n",
    "    \n",
    "    if os.path.isfile(save_model_dir):\n",
    "        model.load_state_dict(torch.load(save_model_dir))\n",
    "        print(save_model_dir, 'loaded')\n",
    "        continue\n",
    "\n",
    "    print(\"epochs:\", epochs, \"learning_rate:\", lr)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "    infer_model, val_acc = util.train(model=model, optimizer=optimizer, epochs=1, train_loader=train_loader, val_loader=val_loader, scheduler=None, device=device, label_smooth=CFG['LABEL_SMOOTH'])\n",
    "    torch.save(model.state_dict(), save_model_dir)\n",
    "\n",
    "    test = pd.read_csv('./test.csv')\n",
    "    test_dataset = util.CustomDataset(test['img_path'].values, None, get_test_transform(CFG['IMG_SIZE_TEST']))\n",
    "    test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=4)\n",
    "\n",
    "    pred = util.inference(model, test_loader, device)\n",
    "    pred = np.array(pred > 0.5, dtype=np.int8)\n",
    "    \n",
    "    submission = pd.read_csv('./sample_submission.csv', index_col=0)\n",
    "    submission.iloc[:,:] = pred\n",
    "    submission.to_csv(save_model_dir.replace('.pth', '.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2076a387d2eeee7d098e4cccefb973249bebb4fa144919220ce31f67b8bf2cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
